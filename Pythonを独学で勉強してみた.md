# Pythonを独学で勉強してみた
こんにちは。初めまして。レッジのインターン生の大見川です。 レッジでは、 データサイエンス部門に所属していますが、 [Ledge.ai](https://ledge.ai/)  というメディアで記事も書いているので良ければご覧ください。

今回の記事では、「これからpythonの勉強をしたい!」という方に向けて、自分の経験を踏まえておすすめの勉強の仕方を書いていきたいと思います。

なぜなら、私自身もインターン生になる前は独学で勉強していたからです。Pythonの勉強を始める前はプログラミングの経験は全くなく、「HTMLって何?」みたいなレベルでしたが、根気よく勉強すればある程度コードが書けるようになってので参考になると思います。

# 1冊目におすすめの本
私が最初に勉強していた本は「Pythonで動かして学ぶ!深層学習の教科書」という本です。正直、図書館で見つけて「これならわかりやすそうだし面白うそうだなー」くらいの感覚で選びましたが、今考えても1冊目にはおすすめです。ここで注意してほしいことが、その本が「最終的に何をできるようになる本なのか」を見て、自分が面白そうだと思うものを選んだ方がいいと思います。なぜなら、プログラミングを勉強する上で(特に独学だと)一番大事なのは根気よく続けることだからです。この本は最終的に画像認識ができるようになることが目標ですが、他にも自然言語処理やデータ分析などPythonで出来る事はたくさんあるので、その中で1番面白そうだと思うテーマを扱っている教材を選んだほうがいいと思います。また、動画で勉強したいという方は[Udemy](https://www.udemy.com/ja/)というサイトがおすすめです。セール中であれば安く購入することができます。


# 全体的な流れ
この本の大まかな流れは
1. **環境構築**
2. **機械学習の説明**
3. **Pythonの文法**
4. **有名なライブラリの紹介**
5. **機械学習の実装**
6. **深層学習の実装**
7. **CNNの実装**
8. **データの水増し・転移学習**

というような流れとなります。ここからはこの順番にそって説明していきます。

## 環境構築
プログラミングの勉強をする時に、まず環境構築をする必要があります。この本では[Anaconda](https://www.anaconda.com/)というパッケージが紹介されています。これを使うと必要なライブラリが簡単にインストールできるようになり便利です。基本的には書いてある通りに操作していけばできると思いますが、途中でつまずいて進めなくなってしまったり、面倒だという方には[Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja)がおすすめです。こちらは、すでにPythonで機械学習の勉強をするために必要な環境は一通りそろっており、後々あると便利なGPUも使えるので、最初からこちらを使った方がいいかもしれません。

## 機械学習の説明
次は「そもそも機械学習とは何か?」という説明から、よく使われる手法などの説明が書かれています。コードを書くことはありませんが、実装するときにも必要となる知識なので、しっかり読んで理解していきましょう。

## Pythonの文法
いよいよ実際にPythonのコードを書いていきます。
まずはPythonの基礎ということで**「変数」「型」「if文」**の説明となります。本書ではそれぞれの項目が説明された後や、章の最後に問題が書かれているので、解いてみてください。読んで理解しても実際に手を動かすと分からないところが出てくると思うので、その度に説明部分を読み返すことが大事だと思います。

次は**「リスト型」「辞書型」「while文」「for文」**の説明です。本に書かれている内容を少しずつ変えてどのように出力されるかを予想してみたり、問題の設定を変えて解いてみたりすると、より理解が深まると思います。

文法の最後は**関数**です。この章ではPythonにもともと組み込まれている関数やメゾットから、自分で関数を定義するところまで学びます。ここで注意してほしいことは、学校のテストとは違い**すべてを覚える必要はない**ということです。例えば簡単な例を出すと、[1,3,5,2,4]というリストにsortというメゾッドを用いると[1,2,3,4,5]というように並び替えることができるのですが、ここでは「なんか並び替えるメゾッドあったなー」くらいの記憶で十分です。メゾッドや組み込み関数は本で紹介されていないものもたくさんありますし、全てを1つずつ覚えていたらきりがないので、今回の例で言えば「Python　並び替え」のように調べれば色々な記事が出てきます。実際に業務をする上でも忘れてしまったら、その度に調べれば良いです。何よりここら辺の文法は(少なくても私は)面白くありませんでした。最初にも書きましたが、独学する上では続けることが大事なので、どんどん進めていきましょう。

## 有名なライブラリの紹介
ここではPythonでよく用いられるライブラリを紹介していきます。ライブラリとは**外部から読み込むPythonのコードの塊**です。わかりにくいと思うので以下の図をご覧ください。今回はベクトル・行列の計算に特化したライブラリである**NumPy**を表しています。

![numpy](https://storage.googleapis.com/techblog/images/python_introduction/numpy.jpg)

NumPyのrandomというモジュールの中randintという関数があるという感じです。この本ではNumPy、Pandas、matplotlibについて説明されています。ここも「そういうものがあるんだ」くらいの理解をして実際にコードを書いていきましょう。

※ここから先は高校〜大学1年程度の数学の知識が必要な場面が出てきます。私は理系なのでそこで困ることはなかったのですが、「プログラミング以前に数学的にわからない」という状況になったら数学の勉強もするしかないです。「高校~大学1年程度の数学」といっても、その範囲の数学が完璧である必要は全くないので、プログラミングの勉強をしながら知らない話が出てきたら調べて勉強する程度で大丈夫です。

### NumPy
[Numpy](https://numpy.org/doc/stable/index.html)の章では主にndarray配列を使って計算をしていきます。このあたりから少しづつ複雑になり、エラーが出てしまうこともあると思います。**エラーが出たらそのエラー文をそのままコピペして検索してみましょう。**多くのエラーは過去に同じ体験をした人が解決方法を書いてくれています。先ほどから「分からなかったり、忘れてしまったら検索」といっていますが、欲しい「情報を検索できる」というのも重要な能力です。
**NumPyは画像処理だけでなくPythonを使う開発であれば、大体使われると思うので、何をやっているのかはしっかり理解していきましょう。**

### Pandas
この章では[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)についての説明がされています。Pandasとは一般的なデータベースにて行われる操作が実行でき、数値以外にも氏名や住所といった文字列データも簡単に扱うことができるライブラリです。なのでデータ分析をする際には欠かせないライブラリとなります。

### matplotlib
この章ではデータの可視化をすることができる[matplotlib](https://matplotlib.org/3.2.1/index.html)というライブラリの説明がされています。データ分析をする上で可視化することは非常に有効な手段の1つであるので、こちらもデータ分析には欠かすことのできないライブラリとなります。

## 機械学習とは
ここまでで基礎的な知識は揃ったので、ようやく**機械学習の実装**に入っていきます。機械学習といっても大きく以下の3種類に分けることができます。

* **教師あり学習**

蓄積されたデータを元に新しいデータや未来のデータ予測、あるいは分類を行う。株価予測や画像認識が当てはまる。

* **教師なし学習**

蓄積されたデータの構造や関係性を見出すことを意味する。
小売店の顧客の傾向分析などで用いられる。


* **強化学習**

報酬や環境などを設定することで学習時に収益の最大化を図るような行動を学習する。
囲碁などの対戦型AIで用いられることが多い。

<div align=“center”>
<img src=“https://storage.googleapis.com/techblog/images/python_introduction/machinelaerning.png”>
</div>


ここでは画像認識を学ぶので、教師あり学習にあたります。
ここでいったん機械学習を実装する流れを大まかに説明すると

1. **データを集める**
2. **データを加工する(前処理)**
3. **モデルを作り、学習させる**
4. **モデルのハイパーパラメータ(細かい設定みたいなもの)を調整する**

となります。ここで注意して欲しいのは、この本(というかほとんどの教材)では主に3と4のモデルを作りパラメータを調整するところをメインに説明されています。データはあらかじめ学習しやすい形に整っているデータセットを使いますが、**実際には2の前処理と言われる作業がかなり時間がかかる**ということは覚えておいてください。この本で言うとデータクレンジングという形で簡単に紹介されています。

また、**深層学習**というのは機械学習の手法の1つであり、3のモデルを作るという場面で登場します。この本では、まず、深層学習ではないモデルで上の流れを1通り紹介して、最後にCNNという画像処理によく使われる深層学習を紹介されています。

## 機械学習の実装
上でも少し触れましたが、この章ではまず、教師学習で用いられる**機械学習のモデル**が数種類紹介されています。また、それぞれのモデルに特有のハイパーパラメータを持っているので、それらの調整(チューニング)をするところまで学ぶことができます。

## 深層学習の実装
ここでは**MNIST**という手書き文字のデータセットを用いて、簡単な深層学習の実装をします。**この章を最後まで読み終えると、手書き数字画像データから数字を判別できるコードを書けるようになります。**具体的にはディープニューラルネットワーク(DNN)という、層が何層にも重なったモデルを作り、DNNのハイパーパラメータをチューニングします。この流れはこれまでのDNN以外の機械学習の流れと同じです。

<div align=“center”>
<img src=“https://storage.googleapis.com/techblog/images/python_introduction/mnist.png”>
</div>

## CNNの実装
ついに最後の、画像認識でよく用いられる**CNN**を実装する章です。画像認識とは、画像や映像に映る文字や顔などいった「モノ」や「特徴」を検出する技術です。具体的には、画像の分類やモノの位置の推定など様々な認識技術が挙げられます。CNNとは畳み込みニューラルネットワークのことでConvolutional Neural Networkの略となります。

CNNは**「畳み込み層」**と**「プーリング層」**と呼ばれる層をいくつも重ねていくことで形成されます。
畳み込み層では、入力データの一部分に注目してその部分画像の特徴を調べます。例えば顔認識をする場合は、適切に学習が進むと、入力層に近い畳み込み層では線や点といった低次元な概念の特徴に、出力層に近い層では目や鼻といった高次元な概念の特徴に注目するようになります。
プーリング層は畳み込み層の出力を縮約しデータの量を削減する層と言えます。畳み込み層での畳み込みを行うと、同じような特徴が近くにあったり、うまく特徴を見つけることができない場所が出てきたりして、畳み込み層からの出力には無駄があります。プーリング層ではそのようなデータの無駄を削減し、情報の損失を押さえながらデータを圧縮します。一方、細かい位置情報などは失われてしまいますが、逆にこれで元の画像の平行移動などの影響を受けにくくなります。例えば、手書き文字認識を行う場合、数字の位置情報はあまり重要ではないのでそれを削除し、位置の変化に強いモデルとなります。

これらの層は[Keras](https://keras.io/ja/)と[TensorFlow](https://www.tensorflow.org/?hl=ja)というライブラリを使うと簡単に実装することができます。ここでは先ほども登場したMNISTに加え、10種類のカラー画像のデータセットである**CIFAR10**を使って、CNNの実装をしていきます。

<div align=“center”>
<img src=“https://storage.googleapis.com/techblog/images/python_introduction/CIFAR-10.png”>
</div>

## データの水増し・転移学習
画像認識では、画像データとそのラベルの組み合わせが大量に必要になります。しかし、モデルを学習させるのに十分な量のデータセットを揃えることができないことは多々あります。そこで、**画像の水増し**というテクニックを使って、持っているデータの量を増やすことができます。具体的には、画像を反転・ずらし・色を変えるなどして、新たなデータを作ります。
この作業もKerasの**ImageDataGenerator**を使うと簡単に実装することができます。ImageDataGeneratorには多くの引数が存在し、それらの値を調節することで、画像を水増しすることができます。

<div align=“center”>
<img src=“https://storage.googleapis.com/techblog/images/python_introduction/imagedatageberator.jpeg”>
</div>

また、大規模なニューラルネットワークを学習させるには、膨大なデータと時間が必要となります。そこで、**「大量のデータですでに学習され公開されているモデルを使って新たなモデルを作ろう」**というものが**転移学習**です。Kerasでは**ImageNet(120万枚、1000クラスの巨大なデータセット)**で学習済みの画像分類モデルとその重みをダウンロードして、使用します。公開されているモデルは数種類ありますが、ここでは**VGG16**というモデルを使います。VGG16は1000クラスの分類モデルなので、出力ユニットは1000個ありますが、最後の全結合層は使わずに途中までの層を特徴抽出のために使用することで転移学習に用いることができます。

<div align=“center”>
<img src=“https://storage.googleapis.com/techblog/images/python_introduction/vgg16.png”>
</div>


# 最後に
今回は、どういう風に勉強したかも交えながら、初めて読んだ本の内容を紹介してみました。前半は基礎的な話でPythonを使う際には必ず必要になる知識だと思います。後半部分は画像認識の話でしたが、ぜひ、これらの技術を使って何かアプリを作ったりしてアウトプットしてみてください。
また、他にも自然言語処理や時系列データの分析などPythonできることは
たくさんあるのでそれらを学んでみるのもいと思います。






